// /api/ask.js
// Vercel Serverless (Node.js) â€” OpenAI ì—°ê²° + ì•ˆì „í•œ fallback í¬í•¨

export const config = { runtime: "edge" }; // Edgeê°€ ë” ë¹ ë¦„. Nodeê°€ í•„ìš”í•˜ë©´ ì œê±°í•˜ê³  default ì‚¬ìš©.

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || process.env.OPENAI_API_TOKEN || "";
const MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini"; // í•„ìš”ì‹œ gpt-4o ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥

// ê³µí†µ ìœ í‹¸
const json = (obj, init = {}) =>
  new Response(JSON.stringify(obj), { status: 200, headers: { "content-type": "application/json" }, ...init });

const bad = (msg, status = 200) =>
  json({ ok: false, error: msg }, { status });

const clamp = (s, n = 4000) => (typeof s === "string" ? s.slice(0, n) : s);

const isNonsense = (q = "") => {
  const t = q.trim().toLowerCase();
  if (!t || t.length < 2) return true;
  if (/^[^a-zA-Zê°€-í£0-9?!. ]+$/.test(t)) return true;          // ê¸°í˜¸ë§Œ
  if (/([a-z])\1{3,}/.test(t)) return true;                    // ê°™ì€ ê¸€ì ë°˜ë³µ
  if (t.split(" ").length <= 1 && !/[?]/.test(t)) return false; // ë‹¨ì–´ 1ê°œëŠ” OK(ì˜ˆ: "career?")
  return false;
};

// OpenAI í˜¸ì¶œ
async function openaiChat(messages, { temperature = 0.7, max_tokens = 400 } = {}) {
  if (!OPENAI_API_KEY) return { ok: false, error: "Missing OPENAI_API_KEY" };

  const body = {
    model: MODEL,
    temperature,
    max_tokens,
    messages
  };

  const r = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "content-type": "application/json",
      authorization: `Bearer ${OPENAI_API_KEY}`
    },
    body: JSON.stringify(body),
    // ê°„ë‹¨í•œ íƒ€ì„ì•„ì›ƒ ë³´í˜¸
    signal: AbortSignal.timeout ? AbortSignal.timeout(25000) : undefined
  });

  const text = await r.text();
  let data = null;
  try { data = JSON.parse(text); } catch { /* ignore */ }

  const content = data?.choices?.[0]?.message?.content?.trim();
  if (r.ok && content) return { ok: true, content, raw: data };
  return { ok: false, error: data?.error?.message || text };
}

// í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
function systemForChat() {
  return {
    role: "system",
    content:
      "You are a friendly Saju (Four Pillars) interpreter for English-speaking users. " +
      "Use the provided chart JSON if available. Answer the user's question directly in 3â€“6 sentences. " +
      "Be clear and practical, avoid generic filler. Offer one useful timing or action and one caution when possible. " +
      "Use approachable language; you may include one emoji if helpful (max one). " +
      "No markdown headings, no asterisks lists; keep it conversational. " +
      "Avoid medical/legal/absolute predictions. Use hedging language when appropriate."
  };
}

function userForChat(question, chart) {
  const ctx = chart ? `Chart JSON (truncated):\n${clamp(JSON.stringify(chart), 3000)}` : "Chart JSON: (not provided)";
  return {
    role: "user",
    content: `${ctx}\n\nQuestion:\n${question}`
  };
}

function systemForTopic(topic) {
  return {
    role: "system",
    content:
      "You are a Saju (Four Pillars) interpreter. Generate concise, useful guidance for the requested topic " +
      "based on the chart JSON if provided. Respond STRICTLY as JSON with keys: overview, phases, watch, tips. " +
      "Each value must be plain text (no markdown, no asterisks). " +
      "overview: 3â€“5 sentences with one tasteful emoji. " +
      "phases: a compact paragraph listing age-phase or cycle highlights separated by ' â€¢ '. " +
      "watch: cautions, also compact with ' â€¢ '. " +
      "tips: practical actions, compact with ' â€¢ '."
  };
}

function userForTopic(topic, chart) {
  const ctx = chart ? `Chart JSON (truncated):\n${clamp(JSON.stringify(chart), 3000)}` : "Chart JSON: (not provided)";
  return {
    role: "user",
    content:
      `${ctx}\n\nTopic: ${topic}\n` +
      "Return JSON only."
  };
}

// ê°„ë‹¨ Fallback (í‚¤ ì—†ê±°ë‚˜ ì¥ì•  ì‹œ)
const FALLBACK_TOPIC = (topic) => ({
  overview: `Hereâ€™s a short ${topic} overview based on common Saju patterns. As cycles shift, focus on steady routines and review your plans quarterly. A small buffer and clear checkpoints go a long way. ğŸ™‚`,
  phases: "0â€“10: build habits â€¢ 20s: learn + network â€¢ 30s: output + ship â€¢ 40s: team + influence â€¢ 50sâ€“60s: consolidation + stewardship",
  watch: "avoid overcommitting â€¢ check assumptions at each phase â€¢ beware of vague offers during high-stress windows",
  tips: "set quarterly goals â€¢ keep a small buffer â€¢ validate before scaling â€¢ journal quick wins to keep momentum"
});

const FALLBACK_CHAT = (q) =>
  `Hereâ€™s a practical take on â€œ${q}â€. Start with the smallest useful step, plan in quarters, and keep a small buffer for surprises. ` +
  `Avoid big commitments during heavyâ€‘stress weeks; batch admin work when energy is low. When in doubt, test small before going allâ€‘in.`;

// ë³¸ë¬¸ íŒŒì„œ (GET/POST ë‘˜ ë‹¤ ì§€ì›)
async function parseRequest(req) {
  const url = new URL(req.url);
  const topic = url.searchParams.get("topic") || null;

  if (req.method === "GET") {
    // /api/ask?topic=wealth
    return { mode: topic ? "topic" : null, topic, q: null, chart: null };
  }

  if (req.method === "POST") {
    let body = {};
    try { body = await req.json(); } catch {}
    const q = body?.q || null;
    const chart = body?.chart || body?.context || null; // í”„ë¡ íŠ¸ì—ì„œ ë„˜ê¸°ë©´ ì‚¬ìš©
    const t = body?.topic || topic || null;
    return { mode: q ? "chat" : t ? "topic" : null, topic: t, q, chart };
  }

  return { mode: null, topic: null, q: null, chart: null };
}

// í•¸ë“¤ëŸ¬
export default async function handler(req) {
  const { mode, topic, q, chart } = await parseRequest(req);

  // ëª¨ë“œ ì—†ìœ¼ë©´ ì•ˆë‚´
  if (!mode) {
    return bad("Specify ?topic=â€¦ on GET for card insights, or POST { q } for chat.");
  }

  // ì˜ë¯¸ ì—†ëŠ” ì…ë ¥ ë°©ì§€
  if (mode === "chat" && isNonsense(q)) {
    return json({
      ok: true,
      output:
        "I couldnâ€™t quite understand that. Could you rephrase your question in a simple way? " +
        "For example: â€œWhen is a good time to move?â€, â€œIs next year favorable for a job change?â€, or â€œAny cautions for finances this quarter?â€"
    });
  }

  // === Topic ì¹´ë“œ ===
  if (mode === "topic") {
    try {
      const messages = [systemForTopic(topic), userForTopic(topic, chart)];
      const r = await openaiChat(messages, { temperature: 0.6, max_tokens: 500 });

      if (r.ok) {
        // JSON íŒŒì‹± ì‹œë„
        let parsed = null;
        try { parsed = JSON.parse(r.content); } catch {}
        if (parsed && typeof parsed === "object") {
          // ìµœì†Œ í‚¤ ë³´ì •
          const merged = {
            overview: parsed.overview || FALLBACK_TOPIC(topic).overview,
            phases: parsed.phases || FALLBACK_TOPIC(topic).phases,
            watch: parsed.watch || FALLBACK_TOPIC(topic).watch,
            tips: parsed.tips || FALLBACK_TOPIC(topic).tips
          };
          return json({ ok: true, output: merged });
        }
      }

      // ì‹¤íŒ¨ì‹œ fallback
      return json({ ok: true, output: FALLBACK_TOPIC(topic), fallback: true });
    } catch (e) {
      return json({ ok: true, output: FALLBACK_TOPIC(topic), fallback: true, note: String(e?.message || e) });
    }
  }

  // === Ask ì±„íŒ… ===
  if (mode === "chat") {
    try {
      const messages = [systemForChat(), userForChat(q, chart)];
      const r = await openaiChat(messages, { temperature: 0.7, max_tokens: 420 });

      if (r.ok) {
        return json({ ok: true, output: r.content });
      }

      // ì‹¤íŒ¨ ì‹œ ì§§ì€ fallback
      return json({ ok: true, output: FALLBACK_CHAT(q), fallback: true });
    } catch (e) {
      return json({ ok: true, output: FALLBACK_CHAT(q), fallback: true, note: String(e?.message || e) });
    }
  }

  // ê·¸ ì™¸
  return bad("Unsupported mode");
}
